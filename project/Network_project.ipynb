{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c62bc32e",
      "metadata": {
        "id": "c62bc32e"
      },
      "source": [
        "# The role of Reddit users in financial market dynamics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install yfinance"
      ],
      "metadata": {
        "id": "ynoXJ11ntBQe"
      },
      "id": "ynoXJ11ntBQe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pyvis"
      ],
      "metadata": {
        "id": "Dzr2Sp6v_QDE"
      },
      "id": "Dzr2Sp6v_QDE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import zstandard\n",
        "import os\n",
        "import json\n",
        "import sys\n",
        "import logging.handlers\n",
        "import re\n",
        "from datetime import datetime, time\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from pyvis.network import Network\n",
        "import time as t"
      ],
      "metadata": {
        "id": "v5A4AF2W3O9r"
      },
      "id": "v5A4AF2W3O9r",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Data transformation"
      ],
      "metadata": {
        "id": "MocsnXN8kG_l"
      },
      "id": "MocsnXN8kG_l"
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting posts\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = 'wallstreetbets_submissions.zst'\n",
        "    output_file_path = 'output.json'\n",
        "    file_size = os.stat(file_path).st_size\n",
        "    file_lines = 0\n",
        "    file_bytes_processed = 0\n",
        "    created = None\n",
        "    field = \"subreddit\"\n",
        "    value = \"wallstreetbets\"\n",
        "    bad_lines = 0\n",
        "    output_data = []\n",
        "\n",
        "    for line, file_bytes_processed in read_lines_zst(file_path):\n",
        "        try:\n",
        "            obj = json.loads(line)\n",
        "            created = datetime.utcfromtimestamp(int(obj['created_utc']))\n",
        "            temp = obj[field] == value\n",
        "            output_data.append(obj)\n",
        "        except (KeyError, json.JSONDecodeError) as err:\n",
        "            bad_lines += 1\n",
        "        file_lines += 1\n",
        "        if file_lines % 100000 == 0:\n",
        "            log.info(f\"{created.strftime('%Y-%m-%d %H:%M:%S')} : {file_lines:,} : {bad_lines:,} : {file_bytes_processed:,}:{(file_bytes_processed / file_size) * 100:.0f}%\")\n",
        "\n",
        "    # Save the JSON data to the output file\n",
        "    with open(output_file_path, 'w') as output_file:\n",
        "        json.dump(output_data, output_file)\n",
        "\n",
        "    log.info(f\"Complete : {file_lines:,} : {bad_lines:,}\")"
      ],
      "metadata": {
        "id": "LvvsFFWlkUqJ"
      },
      "id": "LvvsFFWlkUqJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Key words\n",
        "keywords = ['gme', 'gamestop', 'gamestonk']\n",
        "\n",
        "# Compiling a regular expression pattern for case-insensitive search\n",
        "pattern = re.compile(r'\\b(?:{})\\b'.format('|'.join(re.escape(word) for word in keywords)), re.IGNORECASE)\n",
        "\n",
        "# Filter posts that contain the keywords\n",
        "filtered_posts = [post for post in data if pattern.search(post['title']) or pattern.search(post['selftext'])]"
      ],
      "metadata": {
        "id": "6lkoh4TDkYql"
      },
      "id": "6lkoh4TDkYql",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Edit the date field\n",
        "for post in filtered_posts:\n",
        "    try:\n",
        "        utc_timestamp = int(post['created_utc'])  # Try to convert to integer\n",
        "        post['created_utc'] = datetime.fromtimestamp(utc_timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
        "    except ValueError:  # Skip if conversion fails\n",
        "        pass\n",
        "\n",
        "for post in filtered_posts:\n",
        "    if not isinstance(post['created_utc'], datetime):\n",
        "        post['created_utc'] = datetime.strptime(post['created_utc'], '%Y-%m-%d %H:%M:%S')"
      ],
      "metadata": {
        "id": "Qz0--Mnjkf5Y"
      },
      "id": "Qz0--Mnjkf5Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choosing the right dates\n",
        "start_date = datetime.strptime('2020-11-27', '%Y-%m-%d')\n",
        "end_date = datetime.strptime('2021-02-03', '%Y-%m-%d')\n",
        "\n",
        "filtered_posts_2 = [post for post in filtered_posts if start_date <= post['created_utc'] <= end_date]"
      ],
      "metadata": {
        "id": "gkqlsptDkjRR"
      },
      "id": "gkqlsptDkjRR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the updated list of dictionaries to a JSON file\n",
        "with open('output2.json', 'w') as output_file:\n",
        "    json.dump(filtered_posts_2, output_file)"
      ],
      "metadata": {
        "id": "X4G5tatKkmAh"
      },
      "id": "X4G5tatKkmAh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting comments\n",
        "names = set([d['name'] for d in filtered_posts_2])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = 'wallstreetbets_comments-001.zst'\n",
        "    output_file_path = 'comments3.json'\n",
        "    file_size = os.stat(file_path).st_size\n",
        "    file_lines = 0\n",
        "    file_bytes_processed = 0\n",
        "    created = None\n",
        "    bad_lines = 0\n",
        "    output_data = []\n",
        "\n",
        "    for line, file_bytes_processed in read_lines_zst(file_path):\n",
        "        try:\n",
        "            obj = json.loads(line)\n",
        "            created = datetime.utcfromtimestamp(int(obj['created_utc']))\n",
        "\n",
        "            # Check if 'parent_id' exists in the object and if its value is in the names list\n",
        "            if 'link_id' in obj and obj['link_id'] in names:\n",
        "                output_data.append(obj)\n",
        "\n",
        "        except (KeyError, json.JSONDecodeError) as err:\n",
        "            bad_lines += 1\n",
        "\n",
        "        file_lines += 1\n",
        "        if file_lines % 100000 == 0:\n",
        "            log.info(f\"{created.strftime('%Y-%m-%d %H:%M:%S')} : {file_lines:,} : {bad_lines:,} : {file_bytes_processed:,}:{(file_bytes_processed / file_size) * 100:.0f}%\")\n",
        "\n",
        "    # Save the filtered data to output file\n",
        "    with open(output_file_path, 'w') as output_file:\n",
        "        json.dump(output_data, output_file)\n",
        "\n",
        "    log.info(f\"Complete : {file_lines:,} : {bad_lines:,}\")"
      ],
      "metadata": {
        "id": "Xe1uW0Gpkv5y"
      },
      "id": "Xe1uW0Gpkv5y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data filtering to compress the file\n",
        "\n",
        "with open('comments3.json', 'r') as f:\n",
        "    comments = json.load(f)\n",
        "\n",
        "desired_keys = ['id', \"author\", \"author_fullname\",'body', \"created_utc\", \"parent_id\", \"link_id\", \"subreddit_id\", \"total_awards_received\"]\n",
        "\n",
        "filtered_data = []\n",
        "\n",
        "for item in comments:\n",
        "    filtered_item = {key: item[key] for key in desired_keys if key in item}\n",
        "    filtered_data.append(filtered_item)\n",
        "\n",
        "with open(\"filtered_comments.json\", \"w\") as output_file:\n",
        "    json.dump(filtered_data, output_file, indent=4)\n"
      ],
      "metadata": {
        "id": "H03zq1eS3dcL"
      },
      "id": "H03zq1eS3dcL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "c2c46eb6",
      "metadata": {
        "id": "c2c46eb6"
      },
      "source": [
        "## 1. Data exploration"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# link to the file with submissions  https://drive.google.com/file/d/14DdxjVeTeiohR7JzAITqJiCMJsTPfuZI/view?usp=drive_link\n",
        "\n",
        "! gdown 14DdxjVeTeiohR7JzAITqJiCMJsTPfuZI"
      ],
      "metadata": {
        "id": "BwBj_kK1kmeV"
      },
      "id": "BwBj_kK1kmeV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# link to the filtered file with comments https://drive.google.com/file/d/1xlB1NXwx3FrucWCmyJ_hsq-BnDGfxfYI/view?usp=share_link\n",
        "\n",
        "! gdown 1xlB1NXwx3FrucWCmyJ_hsq-BnDGfxfYI"
      ],
      "metadata": {
        "id": "PYEXWro1k2nN"
      },
      "id": "PYEXWro1k2nN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('output2.json', 'r') as f:\n",
        "    posts = json.load(f)"
      ],
      "metadata": {
        "id": "muyUTrsUk7qJ"
      },
      "id": "muyUTrsUk7qJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('filtered_comments.json', 'r') as f:\n",
        "    comments = json.load(f)"
      ],
      "metadata": {
        "id": "JEz5cvT1k8Ri"
      },
      "id": "JEz5cvT1k8Ri",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the number of posts and comments\n",
        "print('Number of posts:', len(posts))\n",
        "print('Number of comments:', len(comments))"
      ],
      "metadata": {
        "id": "sFZzgf9kpZRk"
      },
      "id": "sFZzgf9kpZRk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# count deleted posts\n",
        "\n",
        "deleted_count = 0\n",
        "\n",
        "# Iterate through the posts and count deleted or removed selftext\n",
        "for post in posts:\n",
        "    if 'selftext' in post and (post['selftext'] == '[deleted]' or post['selftext'] == '[removed]'):\n",
        "        deleted_count += 1\n",
        "\n",
        "print('Number of deleted posts:', deleted_count)"
      ],
      "metadata": {
        "id": "jQptn4Vupebm"
      },
      "id": "jQptn4Vupebm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a pie chart of deleted posts\n",
        "\n",
        "labels = ['Existing posts', 'Removed posts']\n",
        "sizes = [(1 - deleted_count/len(posts)), (deleted_count/len(posts))]\n",
        "colors = ['lightblue', 'gray']\n",
        "\n",
        "plt.figure(figsize=(6, 6))  # Adjust the figure size as needed\n",
        "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
        "plt.title('Share of removed posts', fontsize=15)\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "PQslrqSg-IPm"
      },
      "id": "PQslrqSg-IPm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#count deleted comments\n",
        "\n",
        "deleted_comments = 0\n",
        "\n",
        "# Iterate through the posts and count deleted or removed selftext\n",
        "for comment in comments:\n",
        "    if 'body' in comment and (comment['body'] == '[deleted]' or comment['body'] == '[removed]'):\n",
        "        deleted_comments += 1\n",
        "\n",
        "print('Number of deleted posts:', deleted_comments)"
      ],
      "metadata": {
        "id": "fr2PbneG05aV"
      },
      "id": "fr2PbneG05aV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a pie chart of deleted comments\n",
        "\n",
        "labels = ['Deleted comments', 'Existing comments']\n",
        "sizes = [(deleted_comments/len(comments)), (1 - deleted_comments/len(comments))]\n",
        "colors = ['gray', 'lightblue']\n",
        "\n",
        "plt.figure(figsize=(6, 6))  # Adjust the figure size as needed\n",
        "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\n",
        "plt.title('Share of deleted comments', fontsize=15)\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "zoPR-gt5-Ela"
      },
      "id": "zoPR-gt5-Ela",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0471de3d",
      "metadata": {
        "id": "0471de3d"
      },
      "source": [
        "## Parsing GameStop shares daily prices\n",
        "- Retrieve GameStop daily prices from Yahoo Finance from September 29, 2020 to August 16, 2021 (the main period of Gamestop short squeeze and available reddit data)\n",
        "- We retrieved GameStop daily prices from Yahoo Finance, using the Python library yfinance, and computed the daily price return as the daily relative change, r(t) = p(t)/p(t-1), where p(t) is the Open price at day t.\n",
        "- The period over which our study focuses its attention (from November 27, 2020 to February 3, 2021) includes 99% of the posts and 98% of the comments submitted since January 1, 2016 until February 3, 2021."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f99fd11",
      "metadata": {
        "id": "8f99fd11"
      },
      "outputs": [],
      "source": [
        "# define the ticker for GameStop\n",
        "stock_symbol = \"GME\"\n",
        "\n",
        "# define the start and end dates\n",
        "start_date = datetime(2020, 9, 29)\n",
        "end_date = datetime(2021, 8, 17)\n",
        "\n",
        "#retrieve the data\n",
        "gme_data = yf.download(stock_symbol, start=start_date, end=end_date)\n",
        "\n",
        "gme_prices = pd.DataFrame(gme_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ac8abb9",
      "metadata": {
        "id": "8ac8abb9"
      },
      "outputs": [],
      "source": [
        "#check\n",
        "gme_prices = gme_prices.reset_index()\n",
        "gme_prices.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8cab0d1e",
      "metadata": {
        "id": "8cab0d1e"
      },
      "outputs": [],
      "source": [
        "len(gme_prices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6c8f152",
      "metadata": {
        "id": "d6c8f152"
      },
      "outputs": [],
      "source": [
        "# compute daily relative change, r(t) = p(t)/p(t-1), where p(t) is the Open price at day t.\n",
        "\n",
        "gme_prices['daily_change'] = gme_prices['Open'] / gme_prices['Open'].shift(1)\n",
        "gme_prices['Date'] = pd.to_datetime(gme_prices['Date'])\n",
        "gme_prices.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc00e740",
      "metadata": {
        "scrolled": false,
        "id": "fc00e740"
      },
      "outputs": [],
      "source": [
        "# plot of gme stock prices\n",
        "\n",
        "plt.plot(gme_prices['Date'], gme_prices['daily_change'], marker='', linestyle='-', color='lightblue', linewidth=1)\n",
        "plt.title('Daily Relative Change Over Time')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Daily Relative Change')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "num_ticks = 15\n",
        "max_relative_change = gme_prices['daily_change'].max() - 1  # Subtract 1 to get the range relative to 1\n",
        "min_relative_change = gme_prices['daily_change'].min() - 1\n",
        "step = (max_relative_change - min_relative_change) / (num_ticks - 1)\n",
        "yticks = [1 + i * step for i in range(num_ticks)]  # Add 1 back to the tick values\n",
        "plt.yticks(yticks)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1c94e00",
      "metadata": {
        "id": "e1c94e00"
      },
      "outputs": [],
      "source": [
        "# filter period over which our study focuses its attention (from November 27, 2020 to February 3, 2021)\n",
        "\n",
        "start_date = '2020-11-27'\n",
        "end_date = '2021-02-03'\n",
        "filtered_prices = gme_prices.loc[(gme_prices['Date'] >= start_date) & (gme_prices['Date'] <= end_date)]\n",
        "len(filtered_prices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5ae14cd",
      "metadata": {
        "id": "b5ae14cd"
      },
      "outputs": [],
      "source": [
        "plt.plot(filtered_prices['Date'], filtered_prices['daily_change'], marker='', linestyle='-', color='lightblue', linewidth=1)\n",
        "plt.title('Daily Relative Change Over Time (Nov 27, 2020 - Feb 3, 2021)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Daily Relative Change')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "x_dates = pd.date_range(start='2020-12-01', end='2021-02-02', freq='7D')\n",
        "\n",
        "plt.xticks(x_dates, [date.strftime('%d.%m.%Y') for date in x_dates])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1210b4ad",
      "metadata": {
        "id": "1210b4ad"
      },
      "source": [
        "**Data variables inside post**:\n",
        "- Selftext (body)\n",
        "- Flairs to posts: a set of community-defined tags to define the semantic scope of the post, thus facilitating content search and filtering\n",
        "- Awards to posts or comments to recognize their value. Awards are sold by Reddit for money, they come in a variety of types, and some of them reward the recipient with money or perks such as access to exclusive subreddits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e32c704d",
      "metadata": {
        "id": "e32c704d"
      },
      "outputs": [],
      "source": [
        "with open('gme_submissions.json', 'r') as f:\n",
        "    gme_submissions = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82fc3b9b",
      "metadata": {
        "id": "82fc3b9b"
      },
      "outputs": [],
      "source": [
        "# filtering json file to only keep crucial features\n",
        "\n",
        "fields_to_keep = ['id', \"author\", 'author_flair_text', 'link_flair_css_class',\n",
        "                  'num_comments', 'selftext', 'title', 'retrieved_utc', \"url\", 'created_utc']\n",
        "\n",
        "filtered_data = []\n",
        "for entry in gme_submissions:\n",
        "    filtered_entry = {field: entry.get(field) for field in fields_to_keep}\n",
        "    filtered_data.append(filtered_entry)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0499e4d9",
      "metadata": {
        "id": "0499e4d9"
      },
      "outputs": [],
      "source": [
        "# change the Unix time in created_utc into the datetime\n",
        "\n",
        "for entry in filtered_data:\n",
        "    postdate_str = entry.get('created_utc')\n",
        "    if postdate_str is not None:\n",
        "        postdate = datetime.fromisoformat(postdate_str)\n",
        "        entry['date'] = postdate.date().isoformat()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97436c6f",
      "metadata": {
        "id": "97436c6f"
      },
      "source": [
        "#### (submissions_features.json is the one to continue work with!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7ac9811",
      "metadata": {
        "id": "e7ac9811"
      },
      "outputs": [],
      "source": [
        "# Save the updated data back to the JSON file (submissions_features.json is the one to continue work with!)\n",
        "updated_file_path = 'submissions_features.json'\n",
        "with open(updated_file_path, 'w') as updated_json_file:\n",
        "    json.dump(filtered_data, updated_json_file, indent=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4105d0dc",
      "metadata": {
        "id": "4105d0dc"
      },
      "source": [
        "# 2. Quantifying commitment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dc897b2",
      "metadata": {
        "id": "1dc897b2"
      },
      "outputs": [],
      "source": [
        "with open('submissions_features.json', 'r') as f:\n",
        "    submissions_data = json.load(f)\n",
        "\n",
        "len(submissions_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7b63b33",
      "metadata": {
        "id": "c7b63b33"
      },
      "outputs": [],
      "source": [
        "submissions_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99996dc3",
      "metadata": {
        "id": "99996dc3"
      },
      "source": [
        "#### plot 1: (a) number of posts submitted on WSB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "427d6064",
      "metadata": {
        "id": "427d6064"
      },
      "outputs": [],
      "source": [
        "posts_per_day = {}\n",
        "\n",
        "for entry in submissions_data:\n",
        "    date_str = entry.get('date')\n",
        "    if date_str is not None:\n",
        "        date = datetime.fromisoformat(date_str)\n",
        "        if date.date() in posts_per_day:\n",
        "            posts_per_day[date.date()] += 1\n",
        "        else:\n",
        "            posts_per_day[date.date()] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "370ee7a1",
      "metadata": {
        "id": "370ee7a1"
      },
      "outputs": [],
      "source": [
        "result_data = [{'Date': day, 'n_posts': count} for day, count in posts_per_day.items()]\n",
        "posts_number = pd.DataFrame(result_data)\n",
        "posts_number = posts_number.iloc[:-1,:]\n",
        "posts_number"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6e83261",
      "metadata": {
        "id": "a6e83261"
      },
      "outputs": [],
      "source": [
        "plt.plot(posts_number['Date'], posts_number['n_posts'], marker='', linestyle='-', color='red', linewidth=1)\n",
        "plt.title('N of WSB posts Over Time (Nov 27, 2020 - Feb 3, 2021)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('WSB posts')\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "x_dates = pd.date_range(start='2020-12-01', end='2021-02-02', freq='7D')\n",
        "plt.xticks(x_dates, [date.strftime('%d.%m.%Y') for date in x_dates])\n",
        "\n",
        "plt.yscale('log')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a figure and axis for the first plot\n",
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "# Plot the first data on the left y-axis\n",
        "ax1.plot(posts_number['Date'], posts_number['n_posts'], marker='', linestyle='-', color='red', linewidth=1)\n",
        "ax1.set_ylabel('WSB posts', color='red')\n",
        "ax1.tick_params(axis='y', labelcolor='red')\n",
        "ax1.set_yscale('log')\n",
        "\n",
        "# Create a second y-axis on the left side\n",
        "ax2 = ax1.twinx()\n",
        "\n",
        "# Plot the second data on the right y-axis\n",
        "ax2.plot(filtered_prices['Date'], filtered_prices['daily_change'], marker='', linestyle='-', color='steelblue', linewidth=1)\n",
        "ax2.set_xlabel('Date')\n",
        "ax2.set_ylabel('GME Daily Relative Change', color='steelblue')\n",
        "ax2.tick_params(axis='y', labelcolor='steelblue')\n",
        "ax2.set_title('GME Daily Relative Change and WSB Posts (Nov 27, 2020 - Feb 3, 2021)')\n",
        "\n",
        "# Format x-axis ticks\n",
        "x_dates = pd.date_range(start='2020-12-01', end='2021-02-02', freq='7D')\n",
        "ax1.set_xticks(x_dates)\n",
        "ax1.set_xticklabels([date.strftime('%d.%m.%Y') for date in x_dates], rotation=45)\n",
        "\n",
        "# Add dashed lines for events with adjusted length\n",
        "event_dates = ['08.12.2020', '11.01.2021', '19.01.2021', '26.01.2021']\n",
        "event_labels = ['a', 'b', 'c', 'd']\n",
        "line_length = 0.95  # Adjust the length of the lines\n",
        "\n",
        "for event_date, event_label in zip(event_dates, event_labels):\n",
        "    event_date = pd.to_datetime(event_date, format='%d.%m.%Y')\n",
        "    ax1.axvline(event_date, color='gray', linestyle='--', linewidth=1, ymin=0, ymax=line_length)\n",
        "    ax1.text(event_date, ax1.get_ylim()[1] * 0.7, event_label, va='bottom', ha='center', color='gray')\n",
        "\n",
        "# Ensure that the plots are properly displayed without overlap\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the combined plot\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "gfQ3LF-tOooc"
      },
      "id": "gfQ3LF-tOooc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "fca4c7de",
      "metadata": {
        "id": "fca4c7de"
      },
      "source": [
        "#### plot 2: (b) number of posts on WSB that showed financial commitment (flairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72b19a62",
      "metadata": {
        "scrolled": true,
        "id": "72b19a62"
      },
      "outputs": [],
      "source": [
        "# check flair marks in posts: gain, loss, YOLO in link_flair_css_class\n",
        "### they do not have 'gain', only 'profit' flair\n",
        "\n",
        "flair_counts = {'profit': 0, 'loss': 0, 'yolo': 0}\n",
        "\n",
        "# Iterate through the data entries\n",
        "for entry in submissions_data:\n",
        "    author_flair = entry.get('link_flair_css_class')\n",
        "    if author_flair in flair_counts:\n",
        "        flair_counts[author_flair] += 1\n",
        "\n",
        "# Print the counts for each flair\n",
        "for flair, count in flair_counts.items():\n",
        "    print(f\"{flair}: {count} posts\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2978fe5e",
      "metadata": {
        "id": "2978fe5e"
      },
      "outputs": [],
      "source": [
        "unique_flairs = set()\n",
        "\n",
        "for entry in submissions_data:\n",
        "    author_flair = entry.get('link_flair_css_class')\n",
        "    if author_flair is not None:\n",
        "        unique_flairs.add(author_flair)\n",
        "\n",
        "unique_flairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b08e435e",
      "metadata": {
        "id": "b08e435e"
      },
      "outputs": [],
      "source": [
        "for entry in submissions_data:\n",
        "    date_str = entry.get('date')\n",
        "    if date_str:\n",
        "        entry['date'] = datetime.strptime(date_str, '%Y-%m-%d').date()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6bbac39",
      "metadata": {
        "id": "c6bbac39"
      },
      "outputs": [],
      "source": [
        "submissions_data[0]['date']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a51568b",
      "metadata": {
        "id": "8a51568b"
      },
      "outputs": [],
      "source": [
        "dates = []\n",
        "n_profit = []\n",
        "n_loss = []\n",
        "n_yolo = []\n",
        "\n",
        "specific_flairs = ['profit', 'loss', 'yolo']\n",
        "\n",
        "# Iterate through the data entries\n",
        "for entry in submissions_data:\n",
        "    date = entry.get('date')\n",
        "    flair = entry.get('link_flair_css_class')\n",
        "\n",
        "    if date is not None and flair in specific_flairs:\n",
        "        dates.append(date)\n",
        "        if flair == 'profit':\n",
        "            n_profit.append(1)\n",
        "            n_loss.append(0)\n",
        "            n_yolo.append(0)\n",
        "        elif flair == 'loss':\n",
        "            n_profit.append(0)\n",
        "            n_loss.append(1)\n",
        "            n_yolo.append(0)\n",
        "        elif flair == 'yolo':\n",
        "            n_profit.append(0)\n",
        "            n_loss.append(0)\n",
        "            n_yolo.append(1)\n",
        "\n",
        "# Create a pandas DataFrame\n",
        "flair_counts_df = pd.DataFrame({\n",
        "    'Date': dates,\n",
        "    'n_profit': n_profit,\n",
        "    'n_loss': n_loss,\n",
        "    'n_yolo': n_yolo\n",
        "})\n",
        "\n",
        "# Group by date and sum the counts\n",
        "flair_counts = flair_counts_df.groupby('Date').sum().reset_index()\n",
        "flair_counts['financial_commitments'] = flair_counts['n_profit'] + flair_counts['n_loss'] + flair_counts['n_yolo']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b21217e",
      "metadata": {
        "id": "7b21217e"
      },
      "outputs": [],
      "source": [
        "flair_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c0a0b661",
      "metadata": {
        "id": "c0a0b661"
      },
      "outputs": [],
      "source": [
        "plt.plot(flair_counts['Date'], flair_counts['financial_commitments'], marker='', linestyle='-', color='red', linewidth=1)\n",
        "plt.title('GME commitments events (Nov 27, 2020 - Feb 3, 2021)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('GME commitments events')\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "x_dates = pd.date_range(start='2020-12-01', end='2021-02-02', freq='7D')\n",
        "plt.xticks(x_dates, [date.strftime('%d.%m.%Y') for date in x_dates])\n",
        "\n",
        "plt.yscale('log')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Count of posts by flare and date\n",
        "# Convert list of dictionaries to a Pandas DataFrame\n",
        "df = pd.DataFrame(posts)\n",
        "\n",
        "# Filter rows to include only the flair classes you're interested in\n",
        "df = df[df['link_flair_css_class'].isin(['profit', 'loss', 'yolo'])]\n",
        "\n",
        "# Convert 'created_utc' to datetime format and remove time component\n",
        "df['created_utc'] = pd.to_datetime(df['created_utc']).dt.date\n",
        "\n",
        "# Group the data by 'created_utc' and 'link_flair_css_class' and count the number of occurrences\n",
        "grouped_df = df.groupby(['created_utc', 'link_flair_css_class']).size().reset_index(name='count')\n",
        "\n",
        "# Pivot the DataFrame so that 'link_flair_css_class' values become columns\n",
        "pivot_df = grouped_df.pivot(index='created_utc', columns='link_flair_css_class', values='count').fillna(0)\n",
        "\n",
        "# Plotting the data\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "colors = {\n",
        "    'profit': 'steelblue',\n",
        "    'loss': 'lightseagreen',\n",
        "    'yolo': 'rebeccapurple'\n",
        "}\n",
        "\n",
        "linestyle = {\n",
        "    'profit': '--',\n",
        "    'loss': '-.',\n",
        "    'yolo': '-'\n",
        "}\n",
        "\n",
        "# Plot each line\n",
        "for column in pivot_df.columns:\n",
        "    plt.plot(pivot_df.index, pivot_df[column], label=column, color=colors[column], linestyle=linestyle[column])\n",
        "\n",
        "plt.title('Count of Posts by Flair and Date', fontsize = 15, pad=20)\n",
        "plt.ylabel('Events')\n",
        "\n",
        "# Set y-axis to logarithmic scale\n",
        "plt.yscale(\"log\")\n",
        "\n",
        "# Customize y-ticks\n",
        "plt.yticks([1, 10**1, 10**2, 10**3, 10**4, 10**5], ['0', '$10^1$', '$10^2$', '$10^3$', '$10^4$', '$10^5$'])\n",
        "\n",
        "# Get the current axis\n",
        "ax = plt.gca()\n",
        "\n",
        "# Add dashed lines for events with adjusted length\n",
        "event_dates = ['08.12.2020', '11.01.2021', '19.01.2021', '26.01.2021']\n",
        "line_length = 0.95  # Adjust the length of the lines\n",
        "\n",
        "for event_date, event_label in zip(event_dates, event_labels):\n",
        "    event_date = pd.to_datetime(event_date, format='%d.%m.%Y')\n",
        "    ax.axvline(event_date, color='gray', linestyle='--', linewidth=1, ymin=0, ymax=line_length)\n",
        "    ax.text(event_date, ax.get_ylim()[1] * line_length, event_label, va='bottom', ha='center', color='gray')\n",
        "\n",
        "# Move the legend to the middle of the plot\n",
        "legend = plt.legend(loc='upper center', bbox_to_anchor=(0.5, 0.6), fancybox=False, shadow=False)\n",
        "\n",
        "# Remove the legend border\n",
        "legend.get_frame().set_linewidth(0.0)\n",
        "\n",
        "# Remove the top and right spines by setting their color and linewidth to 'none'\n",
        "ax.spines['top'].set_color('none')\n",
        "ax.spines['right'].set_color('none')\n",
        "\n",
        "for tick in ax.get_xticklabels():\n",
        "    tick.set_rotation(50)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SLt-Oyki64UW"
      },
      "id": "SLt-Oyki64UW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "# Plot the first data on the left y-axis\n",
        "ax1.plot(flair_counts['Date'], flair_counts['financial_commitments'], marker='', linestyle='-',\n",
        "         color='red', linewidth=1)\n",
        "ax1.set_ylabel('GME commitments events', color='red')\n",
        "ax1.tick_params(axis='y', labelcolor='red')\n",
        "ax1.set_yscale('log')\n",
        "\n",
        "# Create a second y-axis on the left side\n",
        "ax2 = ax1.twinx()\n",
        "\n",
        "# Plot the second data on the right y-axis\n",
        "ax2.plot(filtered_prices['Date'], filtered_prices['daily_change'], marker='', linestyle='-', color='steelblue', linewidth=1)\n",
        "ax2.set_xlabel('Date')\n",
        "ax2.set_ylabel('GME Daily Relative Change', color='steelblue')\n",
        "ax2.tick_params(axis='y', labelcolor='steelblue')\n",
        "ax2.set_title('GME commitments events (Nov 27, 2020 - Feb 3, 2021)')\n",
        "\n",
        "# Format x-axis ticks\n",
        "x_dates = pd.date_range(start='2020-12-01', end='2021-02-02', freq='7D')\n",
        "ax1.set_xticks(x_dates)\n",
        "ax1.set_xticklabels([date.strftime('%d.%m.%Y') for date in x_dates], rotation=45)\n",
        "\n",
        "# Add dashed lines for events with adjusted length\n",
        "event_dates = ['08.12.2020', '11.01.2021', '19.01.2021', '26.01.2021']\n",
        "event_labels = ['a', 'b', 'c', 'd']\n",
        "line_length = 0.95  # Adjust the length of the lines\n",
        "\n",
        "for event_date, event_label in zip(event_dates, event_labels):\n",
        "    event_date = pd.to_datetime(event_date, format='%d.%m.%Y')\n",
        "    ax1.axvline(event_date, color='gray', linestyle='--', linewidth=1, ymin=0, ymax=line_length)\n",
        "    ax1.text(event_date, ax1.get_ylim()[1] * 0.65, event_label, va='bottom', ha='center', color='gray')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0uFosAvDOi4_"
      },
      "id": "0uFosAvDOi4_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9078eba8",
      "metadata": {
        "id": "9078eba8"
      },
      "source": [
        "#### plot 3: (c) level of group identity (shaded areas corresponds to two standard errors of the daily average)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8e90e84",
      "metadata": {
        "id": "a8e90e84"
      },
      "source": [
        "- To measure the group identity: for each submission, we calculated the fraction of the first person pronouns that are the plural pronoun “we”, and averaged those fractions across all the submissions of a given day\n",
        "-  we measure identity as the fraction of pronoun we against the number of both we and I pronouns occurring in each submission text body."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa48d86b",
      "metadata": {
        "id": "fa48d86b"
      },
      "outputs": [],
      "source": [
        "removed_body = 0\n",
        "\n",
        "for entry in submissions_data:\n",
        "    body = entry.get('selftext')\n",
        "    if body == '[deleted]' or body == '[removed]' or body == '':\n",
        "        removed_body += 1\n",
        "\n",
        "removed_body"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a64634ac",
      "metadata": {
        "id": "a64634ac"
      },
      "outputs": [],
      "source": [
        "submissions_data[5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7022dc3",
      "metadata": {
        "id": "a7022dc3"
      },
      "outputs": [],
      "source": [
        "# Count occurrences of 'we' and 'I' in selftext\n",
        "\n",
        "pattern = r'\\bI\\b'\n",
        "\n",
        "\n",
        "for entry in submissions_data:\n",
        "    selftext = entry.get('selftext', '')  # Default to an empty string if selftext is not present\n",
        "\n",
        "    # Tokenize the selftext using the regular expression pattern\n",
        "    tokens = re.findall(pattern, selftext, flags=re.IGNORECASE)\n",
        "\n",
        "    # Count occurrences of 'we' and 'I'\n",
        "    we_count = selftext.lower().count('we')\n",
        "    i_count = len(tokens)\n",
        "\n",
        "    entry['we_n'] = we_count\n",
        "    entry['I_n'] = i_count\n",
        "\n",
        "    # Set we_n and I_n to 0 if no occurrences are found\n",
        "    if we_count == 0:\n",
        "        entry['we_n'] = 0\n",
        "    if i_count == 0:\n",
        "        entry['I_n'] = 0\n",
        "\n",
        "\n",
        "    if entry['we_n'] + entry['I_n'] != 0:\n",
        "        entry['identity'] = entry['we_n'] / (entry['we_n'] + entry['I_n'])\n",
        "    else:\n",
        "        entry['identity'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b68fcc9",
      "metadata": {
        "id": "7b68fcc9"
      },
      "outputs": [],
      "source": [
        "identity_not_null = 0\n",
        "\n",
        "for entry in submissions_data:\n",
        "    if entry['identity'] > 0:\n",
        "        identity_not_null += 1\n",
        "\n",
        "identity_not_null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d756b6dc",
      "metadata": {
        "id": "d756b6dc"
      },
      "outputs": [],
      "source": [
        "date_identity_totals = {}\n",
        "date_identity_counts = {}\n",
        "\n",
        "for entry in submissions_data:\n",
        "    date = entry.get('date')\n",
        "    identity = entry.get('identity')\n",
        "\n",
        "    if date is not None and identity is not None:\n",
        "        if date not in date_identity_totals:\n",
        "            date_identity_totals[date] = 0\n",
        "            date_identity_counts[date] = 0\n",
        "\n",
        "        date_identity_totals[date] += identity\n",
        "        date_identity_counts[date] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "136ad1e5",
      "metadata": {
        "id": "136ad1e5"
      },
      "outputs": [],
      "source": [
        "average_identity_data = [{'date': date, 'average_identity': total / count}\n",
        "                         for date in date_identity_totals.keys()\n",
        "                         for total, count in [(date_identity_totals[date], date_identity_counts[date])]\n",
        "                         if count > 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a10b8bc7",
      "metadata": {
        "id": "a10b8bc7"
      },
      "outputs": [],
      "source": [
        "average_identity_df = pd.DataFrame(average_identity_data)\n",
        "average_identity_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00d3fb91",
      "metadata": {
        "id": "00d3fb91"
      },
      "outputs": [],
      "source": [
        "plt.plot(average_identity_df['date'], average_identity_df['average_identity'], marker='',\n",
        "         linestyle='-', color='red', linewidth=1)\n",
        "plt.title('Group identity (Nov 27, 2020 - Feb 3, 2021)')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Group identity')\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "x_dates = pd.date_range(start='2020-12-01', end='2021-02-02', freq='7D')\n",
        "plt.xticks(x_dates, [date.strftime('%d.%m.%Y') for date in x_dates])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "# Plot the first data on the left y-axis\n",
        "ax1.plot(average_identity_df['date'], average_identity_df['average_identity'], marker='',\n",
        "         linestyle='-', color='red', linewidth=1)\n",
        "ax1.set_ylabel('Group identity', color='red')\n",
        "ax1.tick_params(axis='y', labelcolor='red')\n",
        "\n",
        "# Create a second y-axis on the left side\n",
        "ax2 = ax1.twinx()\n",
        "\n",
        "# Plot the second data on the right y-axis\n",
        "ax2.plot(filtered_prices['Date'], filtered_prices['daily_change'], marker='', linestyle='-', color='steelblue', linewidth=1)\n",
        "ax2.set_xlabel('Date')\n",
        "ax2.set_ylabel('GME Daily Relative Change', color='steelblue')\n",
        "ax2.tick_params(axis='y', labelcolor='steelblue')\n",
        "ax2.set_title('GME group identity (Nov 27, 2020 - Feb 3, 2021)')\n",
        "\n",
        "# Format x-axis ticks\n",
        "x_dates = pd.date_range(start='2020-12-01', end='2021-02-02', freq='7D')\n",
        "ax1.set_xticks(x_dates)\n",
        "ax1.set_xticklabels([date.strftime('%d.%m.%Y') for date in x_dates], rotation=45)\n",
        "\n",
        "# Add dashed lines for events with adjusted length\n",
        "event_dates = ['08.12.2020', '11.01.2021', '19.01.2021', '26.01.2021']\n",
        "event_labels = ['a', 'b', 'c', 'd']\n",
        "line_length = 0.95  # Adjust the length of the lines\n",
        "\n",
        "for event_date, event_label in zip(event_dates, event_labels):\n",
        "    event_date = pd.to_datetime(event_date, format='%d.%m.%Y')\n",
        "    ax1.axvline(event_date, color='gray', linestyle='--', linewidth=1, ymin=0, ymax=line_length)\n",
        "    ax1.text(event_date, ax1.get_ylim()[1] * line_length, event_label, va='bottom', ha='center', color='gray')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fqbewzNZOmHv"
      },
      "id": "fqbewzNZOmHv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### plot 4: level of group identity on the base of rewards"
      ],
      "metadata": {
        "id": "JRV_axHCymKt"
      },
      "id": "JRV_axHCymKt"
    },
    {
      "cell_type": "code",
      "source": [
        "#Count awards\n",
        "awards = []\n",
        "\n",
        "for post in posts:\n",
        "    data = {}\n",
        "    if len(post['all_awardings']) != 0:\n",
        "        data['time'] = post['created_utc']\n",
        "        count = 0\n",
        "        for awardings in post['all_awardings']:\n",
        "            price = awardings['count']\n",
        "            count += price\n",
        "        data['price'] = count\n",
        "        awards.append(data)\n",
        "\n",
        "award = pd.DataFrame(awards)\n",
        "award['date'] = pd.to_datetime(award['time'])\n",
        "\n",
        "award['date'] = pd.to_datetime(award['date']).dt.date\n",
        "\n",
        "#group by date and count mean number of awards per post\n",
        "pivot = award.groupby('date')['price'].mean()\n",
        "pivot = pd.DataFrame(pivot).reset_index()"
      ],
      "metadata": {
        "id": "8aVowDCNyXGa"
      },
      "id": "8aVowDCNyXGa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax1 = plt.subplots()\n",
        "\n",
        "plt.yscale('log')\n",
        "\n",
        "# Plot the first data on the left y-axis\n",
        "ax1.plot(pivot['date'], pivot['price'], marker='',\n",
        "         linestyle='-', color='steelblue', linewidth=1, alpha=0.7)\n",
        "ax1.set_ylabel('Awerage number of awards per post', color='steelblue', fontsize=10)\n",
        "ax1.tick_params(axis='y', labelcolor='steelblue')\n",
        "\n",
        "# Create a second y-axis on the left side\n",
        "ax2 = ax1.twinx()\n",
        "\n",
        "# Plot the second data on the right y-axis\n",
        "ax2.plot(filtered_prices['Date'], filtered_prices['daily_change'], marker='', linestyle='dotted', color='black', linewidth=1)\n",
        "ax2.set_xlabel('Date')\n",
        "ax2.set_ylabel('GME Daily Change', color='black', fontsize=10)\n",
        "ax2.tick_params(axis='y', labelcolor='black')\n",
        "ax2.set_title('GME group identity (Nov 27, 2020 - Feb 3, 2021)', pad=15)\n",
        "\n",
        "# Format x-axis ticks\n",
        "x_dates = pd.date_range(start='2020-12-01', end='2021-02-02', freq='7D')\n",
        "ax1.set_xticks(x_dates)\n",
        "ax1.set_xticklabels([date.strftime('%d.%m.%Y') for date in x_dates], rotation=45)\n",
        "\n",
        "# Add dashed lines for events with adjusted length\n",
        "event_dates = ['08.12.2020', '11.01.2021', '19.01.2021', '26.01.2021']\n",
        "event_labels = ['a', 'b', 'c', 'd']\n",
        "line_length = 0.95  # Adjust the length of the lines\n",
        "\n",
        "for event_date, event_label in zip(event_dates, event_labels):\n",
        "    event_date = pd.to_datetime(event_date, format='%d.%m.%Y')\n",
        "    ax1.axvline(event_date, color='gray', linestyle='--', linewidth=1, ymin=0, ymax=line_length)\n",
        "    ax1.text(event_date, ax1.get_ylim()[1] * line_length, event_label, va='bottom', ha='center', color='gray')\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "12Ks6epN0lAW"
      },
      "id": "12Ks6epN0lAW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "b40c93aa",
      "metadata": {
        "id": "b40c93aa"
      },
      "source": [
        "# 3 Building Network"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('output2.json', 'r') as f:\n",
        "    posts = json.load(f)\n",
        "\n",
        "with open('filtered_comments.json', 'r') as f:\n",
        "    comments = json.load(f)\n",
        "\n",
        "for d in comments:\n",
        "    if 'parent_id' in d:\n",
        "        d['parent_id'] = d['parent_id'][3:]\n",
        "        d['link_id'] = d['link_id'][3:]\n",
        "\n",
        "for post in comments:\n",
        "    try:\n",
        "        utc_timestamp = int(post['created_utc'])  # Try to convert to integer\n",
        "        post['created_utc'] = datetime.fromtimestamp(utc_timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
        "    except ValueError:  # Skip if conversion fails\n",
        "        pass\n",
        "\n",
        "    post['created_utc'] = datetime.strptime(post['created_utc'], '%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "start_date = datetime(2020, 11, 27, 0, 0, 0)\n",
        "end_date = datetime(2021, 2, 3, 23, 59, 59)\n",
        "\n",
        "comments = [item for item in comments if start_date <= item['created_utc'] <= end_date]\n",
        "\n",
        "comments = sorted(comments, key=lambda x: x['created_utc'])"
      ],
      "metadata": {
        "id": "Fq0YtANklb23"
      },
      "id": "Fq0YtANklb23",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 The whole network"
      ],
      "metadata": {
        "id": "4-NPhVPjlkd_"
      },
      "id": "4-NPhVPjlkd_"
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.DiGraph()\n",
        "\n",
        "# Create a dictionary for fast lookup\n",
        "post_dict = {d['id']: d for d in posts}\n",
        "comment_dict = {d['id']: d for d in comments}\n",
        "\n",
        "for comment in comments:\n",
        "    author = comment['author']\n",
        "    parent_id = comment['parent_id']\n",
        "\n",
        "    # Efficiently find parent comment or post\n",
        "    parent_comment = post_dict.get(parent_id, comment_dict.get(parent_id, None))\n",
        "\n",
        "    if parent_comment is None:\n",
        "        print(f\"Parent not found for id {parent_id}\")\n",
        "        continue\n",
        "\n",
        "    author_parent = parent_comment['author']\n",
        "\n",
        "    # Add nodes and edge\n",
        "    G.add_node(author)\n",
        "    G.add_node(author_parent)\n",
        "    G.add_edge(author, author_parent)"
      ],
      "metadata": {
        "id": "Bx8lojCSlmaw"
      },
      "id": "Bx8lojCSlmaw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G.number_of_nodes()"
      ],
      "metadata": {
        "id": "ZeUSGtI7lo8b"
      },
      "id": "ZeUSGtI7lo8b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G.number_of_edges()"
      ],
      "metadata": {
        "id": "DkXefYfXlqfI"
      },
      "id": "DkXefYfXlqfI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Window of 3000 nodes"
      ],
      "metadata": {
        "id": "_pAJFlAIlt1g"
      },
      "id": "_pAJFlAIlt1g"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Slice Jan 8-12"
      ],
      "metadata": {
        "id": "wixSXEiHlzHM"
      },
      "id": "wixSXEiHlzHM"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the target date and time range\n",
        "start_date = datetime.strptime('2021-01-08', '%Y-%m-%d').date()\n",
        "end_date = datetime.strptime('2021-01-12', '%Y-%m-%d').date()\n",
        "start_time = time(1, 0)\n",
        "end_time = time(18, 0)\n",
        "\n",
        "filtered_comments = []\n",
        "\n",
        "for post in comments:\n",
        "    created_utc = post['created_utc']\n",
        "\n",
        "    if not isinstance(created_utc, datetime):\n",
        "        try:\n",
        "            # Try the first format\n",
        "            created_utc = datetime.strptime(post['created_utc'], '%Y-%m-%d %H:%M:%S')\n",
        "        except ValueError:\n",
        "            try:\n",
        "                # Try the second format\n",
        "                created_utc = datetime.strptime(post['created_utc'], '%Y-%m-%dT%H:%M:%S')\n",
        "            except ValueError:\n",
        "                # Handle other errors, such as skipping the item or raising an error\n",
        "                print(f\"Unknown datetime format for {post['created_utc']}\")\n",
        "                continue\n",
        "\n",
        "    # Extract date and time\n",
        "    post_date = created_utc.date()\n",
        "    post_time = created_utc.time()\n",
        "\n",
        "    # Check if the post falls within the target date and time range\n",
        "    if start_date <= post_date <= end_date and start_time <= post_time <= end_time:\n",
        "        filtered_comments.append(post)"
      ],
      "metadata": {
        "id": "MdNIiQC0tcCd"
      },
      "id": "MdNIiQC0tcCd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation with Networkx\n",
        "G = nx.Graph()\n",
        "\n",
        "# Create a dictionary for fast lookup\n",
        "post_dict = {d['id']: d for d in posts}\n",
        "comment_dict = {d['id']: d for d in comments}\n",
        "\n",
        "for comment in filtered_comments:\n",
        "    author = comment['author']\n",
        "    parent_id = comment['parent_id']\n",
        "\n",
        "    # Efficiently find parent comment or post\n",
        "    parent_comment = post_dict.get(parent_id, comment_dict.get(parent_id, None))\n",
        "\n",
        "    if parent_comment is None:\n",
        "        print(f\"Parent not found for id {parent_id}\")\n",
        "        continue\n",
        "\n",
        "    author_parent = parent_comment['author']\n",
        "\n",
        "    # Determine node color based on link_flair_css_class\n",
        "    flair_class = parent_comment.get('link_flair_css_class', None)\n",
        "    if flair_class in ['profit', 'loss', 'yolo']:\n",
        "        node_color = 'red'\n",
        "    else:\n",
        "        node_color = 'lightgray'\n",
        "\n",
        "    G.add_node(author, color='lightgray')\n",
        "    G.add_node(author_parent, color=node_color)  # Note: This will overwrite the color if the node already exists\n",
        "    G.add_edge(author, author_parent)\n",
        "\n",
        "# Remove self-loops from the graph if they exist\n",
        "G.remove_edges_from(nx.selfloop_edges(G))\n",
        "\n",
        "# Calculate the k-shell value for each node\n",
        "k_shell = nx.core_number(G)\n",
        "\n",
        "# Create a mapping of node sizes based on k-shell values\n",
        "node_sizes = [2**k_shell[node] for node in G.nodes()]"
      ],
      "metadata": {
        "id": "zd2tsxyG7eof"
      },
      "id": "zd2tsxyG7eof",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new figure\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "\n",
        "# Draw the graph with spring_layout\n",
        "pos = nx.spring_layout(G, k=0.05)\n",
        "\n",
        "# Separate red and non-red nodes\n",
        "red_nodes = [node for node, data in G.nodes(data=True) if data.get('color') == 'red']\n",
        "non_red_nodes = [node for node, data in G.nodes(data=True) if data.get('color') != 'red']\n",
        "\n",
        "#set size\n",
        "red_sizes = [2**k_shell[node] for node in red_nodes]\n",
        "non_red_sizes = [2**k_shell[node] for node in non_red_nodes]\n",
        "\n",
        "# Draw non-red nodes first\n",
        "nx.draw_networkx_nodes(\n",
        "    G,\n",
        "    pos,\n",
        "    nodelist=non_red_nodes,\n",
        "    node_color='lightgray',\n",
        "    node_size=non_red_sizes,\n",
        "    ax=ax\n",
        ")\n",
        "\n",
        "# Draw red nodes on top\n",
        "nx.draw_networkx_nodes(\n",
        "    G,\n",
        "    pos,\n",
        "    nodelist=red_nodes,\n",
        "    node_color='firebrick',\n",
        "    node_size=red_sizes,\n",
        "    ax=ax\n",
        ")\n",
        "\n",
        "# Draw edges\n",
        "nx.draw_networkx_edges(G, pos, edge_color='gray', alpha=0.5, width=0.3, ax=ax)\n",
        "ax.collections[0].set_edgecolor(\"darkgray\")\n",
        "\n",
        "# Remove the border of the plot\n",
        "ax.spines['top'].set_visible(False)\n",
        "ax.spines['right'].set_visible(False)\n",
        "ax.spines['bottom'].set_visible(False)\n",
        "ax.spines['left'].set_visible(False)\n",
        "\n",
        "# Show the graph\n",
        "plt.show();"
      ],
      "metadata": {
        "id": "ghA3-t218IK-"
      },
      "id": "ghA3-t218IK-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualisation with pyvis\n",
        "G = nx.DiGraph()\n",
        "\n",
        "# Create a dictionary for fast lookup\n",
        "post_dict = {d['id']: d for d in posts}\n",
        "comment_dict = {d['id']: d for d in comments}\n",
        "\n",
        "for comment in filtered_comments:\n",
        "    author = comment['author']\n",
        "    parent_id = comment['parent_id']\n",
        "\n",
        "    # Efficiently find parent comment or post\n",
        "    parent_comment = post_dict.get(parent_id, comment_dict.get(parent_id, None))\n",
        "\n",
        "    if parent_comment is None:\n",
        "        print(f\"Parent not found for id {parent_id}\")\n",
        "        continue\n",
        "\n",
        "    author_parent = parent_comment['author']\n",
        "\n",
        "    # Determine node color based on link_flair_css_class\n",
        "    flair_class = parent_comment.get('link_flair_css_class', None)\n",
        "    if flair_class in ['profit', 'loss', 'yolo']:\n",
        "        node_color = 'red'\n",
        "    else:\n",
        "        node_color = 'grey'\n",
        "\n",
        "    G.add_node(author, color={'border': 'darkgrey', 'background': 'grey'})\n",
        "    G.add_node(author_parent, color={'border': 'darkgrey', 'background': node_color})  # Note: This will overwrite the color if the node already exists\n",
        "    G.add_edge(author, author_parent)\n",
        "\n",
        "# Remove self-loops from the graph if they exist\n",
        "G.remove_edges_from(nx.selfloop_edges(G))\n",
        "\n",
        "# Calculate the k-shell value for each node\n",
        "k_shell = nx.core_number(G)\n",
        "\n",
        "# Add the k-shell values as attributes to the nodes\n",
        "nx.set_node_attributes(G, k_shell, 'value')\n",
        "\n",
        "# Determine the maximum k-shell value in the graph\n",
        "max_k_shell = max(k_shell.values())\n",
        "\n",
        "# Define a scaling factor for node size\n",
        "size_scale = 4  # You can adjust this value based on your preferences\n",
        "\n",
        "# Create a mapping of node sizes based on k-shell values\n",
        "node_sizes = [size_scale * (max_k_shell - k_shell[node] + 1) for node in G.nodes()]"
      ],
      "metadata": {
        "id": "j9N4Tne_td-8"
      },
      "id": "j9N4Tne_td-8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Network(notebook=True)\n",
        "net.from_nx(G)\n",
        "net.show('example1.html')"
      ],
      "metadata": {
        "id": "a3Le6sd-tjUa"
      },
      "id": "a3Le6sd-tjUa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.4 Slice Jan 21, 16h-17h"
      ],
      "metadata": {
        "id": "HQwx0YEetmjS"
      },
      "id": "HQwx0YEetmjS"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the target date and time range\n",
        "start_date = datetime.strptime('2021-01-21', '%Y-%m-%d').date()\n",
        "end_date = datetime.strptime('2021-01-21', '%Y-%m-%d').date()\n",
        "start_time = time(16, 0)\n",
        "end_time = time(17, 30)\n",
        "\n",
        "filtered_comments = []\n",
        "\n",
        "for post in comments:\n",
        "    created_utc = post['created_utc']\n",
        "\n",
        "    if not isinstance(created_utc, datetime):\n",
        "        try:\n",
        "            # Try the first format\n",
        "            created_utc = datetime.strptime(post['created_utc'], '%Y-%m-%d %H:%M:%S')\n",
        "        except ValueError:\n",
        "            try:\n",
        "                # Try the second format\n",
        "                created_utc = datetime.strptime(post['created_utc'], '%Y-%m-%dT%H:%M:%S')\n",
        "            except ValueError:\n",
        "                # Handle other errors, such as skipping the item or raising an error\n",
        "                print(f\"Unknown datetime format for {post['created_utc']}\")\n",
        "                continue\n",
        "\n",
        "    # Extract date and time\n",
        "    post_date = created_utc.date()\n",
        "    post_time = created_utc.time()\n",
        "\n",
        "    # Check if the post falls within the target date and time range\n",
        "    if start_date <= post_date <= end_date and start_time <= post_time <= end_time:\n",
        "        filtered_comments.append(post)"
      ],
      "metadata": {
        "id": "L7fe1cA5tvym"
      },
      "id": "L7fe1cA5tvym",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.DiGraph()\n",
        "\n",
        "# Create a dictionary for fast lookup\n",
        "post_dict = {d['id']: d for d in posts}\n",
        "comment_dict = {d['id']: d for d in comments}\n",
        "\n",
        "for comment in filtered_comments:\n",
        "    author = comment['author']\n",
        "    parent_id = comment['parent_id']\n",
        "\n",
        "    # Efficiently find parent comment or post\n",
        "    parent_comment = post_dict.get(parent_id, comment_dict.get(parent_id, None))\n",
        "\n",
        "    if parent_comment is None:\n",
        "        print(f\"Parent not found for id {parent_id}\")\n",
        "        continue\n",
        "\n",
        "    author_parent = parent_comment['author']\n",
        "\n",
        "    # Determine node color based on link_flair_css_class\n",
        "    flair_class = parent_comment.get('link_flair_css_class', None)\n",
        "    if flair_class in ['profit', 'loss', 'yolo']:\n",
        "        node_color = 'red'\n",
        "    else:\n",
        "        node_color = 'grey'\n",
        "\n",
        "    G.add_node(author, color={'border': 'darkgrey', 'background': 'grey'})\n",
        "    G.add_node(author_parent, color={'border': 'darkgrey', 'background': node_color})  # Note: This will overwrite the color if the node already exists\n",
        "    G.add_edge(author, author_parent)\n",
        "\n",
        "# Remove self-loops from the graph if they exist\n",
        "G.remove_edges_from(nx.selfloop_edges(G))\n",
        "\n",
        "# Calculate the k-shell value for each node\n",
        "k_shell = nx.core_number(G)\n",
        "\n",
        "# Add the k-shell values as attributes to the nodes\n",
        "nx.set_node_attributes(G, k_shell, 'value')\n",
        "\n",
        "# Determine the maximum k-shell value in the graph\n",
        "max_k_shell = max(k_shell.values())\n",
        "\n",
        "# Define a scaling factor for node size\n",
        "size_scale = 4  # You can adjust this value based on your preferences\n",
        "\n",
        "# Create a mapping of node sizes based on k-shell values\n",
        "node_sizes = [size_scale * (max_k_shell - k_shell[node] + 1) for node in G.nodes()]"
      ],
      "metadata": {
        "id": "6RlBg8NWt1-o"
      },
      "id": "6RlBg8NWt1-o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Network(notebook=True)\n",
        "net.from_nx(G)\n",
        "net.show('example.html')"
      ],
      "metadata": {
        "id": "2KHmxv9Lt4p6"
      },
      "id": "2KHmxv9Lt4p6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.5 Slice Jan 23, 8h-14h"
      ],
      "metadata": {
        "id": "ar-WruWemQR7"
      },
      "id": "ar-WruWemQR7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the target date and time range\n",
        "start_date = datetime.strptime('2021-01-23', '%Y-%m-%d').date()\n",
        "end_date = datetime.strptime('2021-01-23', '%Y-%m-%d').date()\n",
        "start_time = time(8, 0)\n",
        "end_time = time(14, 30)\n",
        "\n",
        "filtered_comments = []\n",
        "\n",
        "for post in comments:  # Assuming 'comments' is a list of dictionaries containing 'created_utc'\n",
        "    # Ensure the 'created_utc' is a datetime object, convert it if it's a string or timestamp\n",
        "    created_utc = post['created_utc']\n",
        "\n",
        "    if not isinstance(created_utc, datetime):\n",
        "        try:\n",
        "            # Try the first format\n",
        "            created_utc = datetime.strptime(post['created_utc'], '%Y-%m-%d %H:%M:%S')\n",
        "        except ValueError:\n",
        "            try:\n",
        "                # Try the second format\n",
        "                created_utc = datetime.strptime(post['created_utc'], '%Y-%m-%dT%H:%M:%S')\n",
        "            except ValueError:\n",
        "                # Handle other errors, such as skipping the item or raising an error\n",
        "                print(f\"Unknown datetime format for {post['created_utc']}\")\n",
        "                continue\n",
        "\n",
        "    # Extract date and time\n",
        "    post_date = created_utc.date()\n",
        "    post_time = created_utc.time()\n",
        "\n",
        "    # Check if the post falls within the target date and time range\n",
        "    if start_date <= post_date <= end_date and start_time <= post_time <= end_time:\n",
        "        filtered_comments.append(post)"
      ],
      "metadata": {
        "id": "nqArUtugt8ai"
      },
      "id": "nqArUtugt8ai",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.DiGraph()\n",
        "\n",
        "# Create a dictionary for fast lookup\n",
        "post_dict = {d['id']: d for d in posts}\n",
        "comment_dict = {d['id']: d for d in comments}\n",
        "\n",
        "for comment in filtered_comments:\n",
        "    author = comment['author']\n",
        "    parent_id = comment['parent_id']\n",
        "\n",
        "    # Efficiently find parent comment or post\n",
        "    parent_comment = post_dict.get(parent_id, comment_dict.get(parent_id, None))\n",
        "\n",
        "    if parent_comment is None:\n",
        "        print(f\"Parent not found for id {parent_id}\")\n",
        "        continue\n",
        "\n",
        "    author_parent = parent_comment['author']\n",
        "\n",
        "    # Determine node color based on link_flair_css_class\n",
        "    flair_class = parent_comment.get('link_flair_css_class', None)\n",
        "    if flair_class in ['profit', 'loss', 'yolo']:\n",
        "        node_color = 'red'\n",
        "    else:\n",
        "        node_color = 'grey'\n",
        "\n",
        "    G.add_node(author, color={'border': 'darkgrey', 'background': 'grey'})\n",
        "    G.add_node(author_parent, color={'border': 'darkgrey', 'background': node_color})  # Note: This will overwrite the color if the node already exists\n",
        "    G.add_edge(author, author_parent)\n",
        "\n",
        "# Remove self-loops from the graph if they exist\n",
        "G.remove_edges_from(nx.selfloop_edges(G))\n",
        "\n",
        "# Calculate the k-shell value for each node\n",
        "k_shell = nx.core_number(G)\n",
        "\n",
        "# Add the k-shell values as attributes to the nodes\n",
        "nx.set_node_attributes(G, k_shell, 'value')\n",
        "\n",
        "# Determine the maximum k-shell value in the graph\n",
        "max_k_shell = max(k_shell.values())\n",
        "\n",
        "# Define a scaling factor for node size\n",
        "size_scale = 4  # You can adjust this value based on your preferences\n",
        "\n",
        "# Create a mapping of node sizes based on k-shell values\n",
        "node_sizes = [size_scale * (max_k_shell - k_shell[node] + 1) for node in G.nodes()]"
      ],
      "metadata": {
        "id": "hyRkwE9Ft-kZ"
      },
      "id": "hyRkwE9Ft-kZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = Network(notebook=True)\n",
        "net.from_nx(G)\n",
        "net.show('example.html')"
      ],
      "metadata": {
        "id": "YcRTheF9uCJ2"
      },
      "id": "YcRTheF9uCJ2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Metrics"
      ],
      "metadata": {
        "id": "Y-Jq9jPTuJFl"
      },
      "id": "Y-Jq9jPTuJFl"
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data\n",
        "G = nx.DiGraph()\n",
        "reciprocity = []\n",
        "heterogeneity_1 = []\n",
        "heterogeneity_2 = []\n",
        "average_degrees = []\n",
        "data = []\n",
        "\n",
        "post_dict = {d['id']: d for d in posts}\n",
        "comment_dict = {d['id']: d for d in comments}\n",
        "\n",
        "first_date = comments[0]['created_utc']\n",
        "last_date = comments[-1]['created_utc']\n",
        "next_date = first_date\n",
        "\n",
        "current_date = first_date\n",
        "\n",
        "while next_date <= last_date:\n",
        "    next_date = current_date + timedelta(days=7)\n",
        "\n",
        "    # Efficient slicing using list comprehensions\n",
        "    comments_in_window = [comment for comment in comments if current_date <= comment['created_utc'] < next_date]\n",
        "\n",
        "    edges_to_add = []\n",
        "\n",
        "    for comment in comments_in_window:\n",
        "        author = comment['author']\n",
        "        parent_id = comment['parent_id']\n",
        "\n",
        "        parent_comment = post_dict.get(parent_id, comment_dict.get(parent_id, None))\n",
        "\n",
        "        if parent_comment is None:\n",
        "            print(f\"Parent not found for id {parent_id}\")\n",
        "            continue\n",
        "\n",
        "        author_parent = parent_comment['author']\n",
        "        edges_to_add.append((author, author_parent))\n",
        "\n",
        "    G.add_edges_from(edges_to_add)\n",
        "\n",
        "    # Check if the graph is not empty\n",
        "\n",
        "    if len(G) > 0:\n",
        "        reciprocity.append(nx.reciprocity(G))\n",
        "\n",
        "        total_degree = sum(dict(G.degree()).values())\n",
        "        average_degree = total_degree / len(G)\n",
        "        average_degrees.append(average_degree)\n",
        "\n",
        "        degrees = np.array([d for n, d in G.degree()])\n",
        "        N = len(degrees)\n",
        "\n",
        "        if N > 0:  # Check to prevent division by zero\n",
        "            first_moment = np.mean(degrees)\n",
        "            second_moment = np.mean(degrees ** 2)\n",
        "            kappa = second_moment / (first_moment ** 2)\n",
        "            heterogeneity_1.append(kappa)\n",
        "            heterogeneity_2.append(np.var(degrees)/(first_moment ** 2))\n",
        "\n",
        "    data.append(next_date)\n",
        "    G.clear()\n",
        "\n",
        "    # Move to the next 1-day window\n",
        "    current_date = current_date + timedelta(days=1)"
      ],
      "metadata": {
        "id": "wigoYsESueHC"
      },
      "id": "wigoYsESueHC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rolling_window = 2  # 7-day rolling window\n",
        "df = pd.DataFrame({'reciprocity': reciprocity, 'heterogeneity_1': heterogeneity_1, 'heterogeneity_2': heterogeneity_2, 'date': data, 'log_heterogeneity_2': np.log(heterogeneity_2), 'average_degrees': average_degrees})\n",
        "df.set_index('date', inplace=True)\n",
        "rolling_mean = df.rolling(window=rolling_window).mean()\n",
        "rolling_std = df.rolling(window=rolling_window).std()\n",
        "\n",
        "upper_bound = rolling_mean + 2 * rolling_std\n",
        "lower_bound = rolling_mean - 2 * rolling_std"
      ],
      "metadata": {
        "id": "OUnlRR0kuyqK"
      },
      "id": "OUnlRR0kuyqK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lower = lower_bound['reciprocity']\n",
        "upper = upper_bound['reciprocity']\n",
        "\n",
        "plt.plot(data, reciprocity)\n",
        "ax1 = plt.gca()  # Get current axis\n",
        "\n",
        "# Adding shaded area for 2 standard deviations around the mean\n",
        "plt.fill_between(data, lower, upper, color='lightblue', alpha=0.5)\n",
        "\n",
        "# Add dashed lines for events with adjusted length\n",
        "event_dates = ['08.12.2020', '11.01.2021', '19.01.2021', '26.01.2021']\n",
        "event_labels = ['a', 'b', 'c', 'd']\n",
        "line_length = 0.90\n",
        "\n",
        "for event_date, event_label in zip(event_dates, event_labels):\n",
        "    event_date = pd.to_datetime(event_date, format='%d.%m.%Y')\n",
        "    ax1.axvline(event_date, color='gray', linestyle='--', linewidth=1, ymin=0, ymax=line_length)\n",
        "    ax1.text(event_date, ax1.get_ylim()[1] * 0.97, event_label, va='bottom', ha='center', color='black')\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8nd9P1Ubu0wW"
      },
      "id": "8nd9P1Ubu0wW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lower = lower_bound['heterogeneity_1']\n",
        "upper = upper_bound['heterogeneity_1']\n",
        "\n",
        "plt.plot(data, heterogeneity_1, color = 'red')\n",
        "ax1 = plt.gca()  # Get current axis\n",
        "\n",
        "# Adding shaded area for 2 standard deviations around the mean\n",
        "plt.fill_between(data, lower, upper, color='#FF8080', alpha=0.5)\n",
        "\n",
        "# Add dashed lines for events with adjusted length\n",
        "event_dates = ['08.12.2020', '11.01.2021', '19.01.2021', '26.01.2021']\n",
        "event_labels = ['a', 'b', 'c', 'd']\n",
        "line_length = 0.90\n",
        "\n",
        "for event_date, event_label in zip(event_dates, event_labels):\n",
        "    event_date = pd.to_datetime(event_date, format='%d.%m.%Y')\n",
        "    ax1.axvline(event_date, color='gray', linestyle='--', linewidth=1, ymin=0, ymax=line_length)\n",
        "    ax1.text(event_date, ax1.get_ylim()[1] * 0.92, event_label, va='bottom', ha='center', color='black')\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kkV4x8WPu3e6"
      },
      "id": "kkV4x8WPu3e6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lower = lower_bound['heterogeneity_2']\n",
        "upper = upper_bound['heterogeneity_2']\n",
        "\n",
        "plt.plot(data, heterogeneity_2, color = 'red')\n",
        "ax1 = plt.gca()  # Get current axis\n",
        "\n",
        "# Adding shaded area for 2 standard deviations around the mean\n",
        "plt.fill_between(data, lower, upper, color='#FF8080', alpha=0.5)\n",
        "\n",
        "# Add dashed lines for events with adjusted length\n",
        "event_dates = ['08.12.2020', '11.01.2021', '19.01.2021', '26.01.2021']\n",
        "event_labels = ['a', 'b', 'c', 'd']\n",
        "line_length = 0.90\n",
        "\n",
        "for event_date, event_label in zip(event_dates, event_labels):\n",
        "    event_date = pd.to_datetime(event_date, format='%d.%m.%Y')\n",
        "    ax1.axvline(event_date, color='gray', linestyle='--', linewidth=1, ymin=0, ymax=line_length)\n",
        "    ax1.text(event_date, ax1.get_ylim()[1] * 0.92, event_label, va='bottom', ha='center', color='black')\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qtj9P5uqu6qU"
      },
      "id": "qtj9P5uqu6qU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lower = lower_bound['log_heterogeneity_2']\n",
        "upper = upper_bound['log_heterogeneity_2']\n",
        "\n",
        "plt.plot(data, np.log(heterogeneity_2), color = 'red')\n",
        "ax1 = plt.gca()  # Get current axis\n",
        "\n",
        "# Adding shaded area for 2 standard deviations around the mean\n",
        "plt.fill_between(data, lower, upper, color='#FF8080', alpha=0.5)\n",
        "\n",
        "# Add dashed lines for events with adjusted length\n",
        "event_dates = ['08.12.2020', '11.01.2021', '19.01.2021', '26.01.2021']\n",
        "event_labels = ['a', 'b', 'c', 'd']\n",
        "line_length = 0.90\n",
        "\n",
        "for event_date, event_label in zip(event_dates, event_labels):\n",
        "    event_date = pd.to_datetime(event_date, format='%d.%m.%Y')\n",
        "    ax1.axvline(event_date, color='gray', linestyle='--', linewidth=1, ymin=0, ymax=line_length)\n",
        "    ax1.text(event_date, ax1.get_ylim()[1] * 0.92, event_label, va='bottom', ha='center', color='black')\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rNKPc3K_u95X"
      },
      "id": "rNKPc3K_u95X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lower = lower_bound['average_degrees']\n",
        "upper = upper_bound['average_degrees']\n",
        "\n",
        "plt.plot(data, average_degrees, color = 'purple')\n",
        "ax1 = plt.gca()  # Get current axis\n",
        "\n",
        "# Adding shaded area for 2 standard deviations around the mean\n",
        "plt.fill_between(data, lower, upper, color='#AB82FF', alpha=0.5)\n",
        "\n",
        "# Add dashed lines for events with adjusted length\n",
        "event_dates = ['08.12.2020', '11.01.2021', '19.01.2021', '26.01.2021']\n",
        "event_labels = ['a', 'b', 'c', 'd']\n",
        "line_length = 0.90\n",
        "\n",
        "for event_date, event_label in zip(event_dates, event_labels):\n",
        "    event_date = pd.to_datetime(event_date, format='%d.%m.%Y')\n",
        "    ax1.axvline(event_date, color='gray', linestyle='--', linewidth=1, ymin=0, ymax=line_length)\n",
        "    ax1.text(event_date, ax1.get_ylim()[1] * 0.92, event_label, va='bottom', ha='center', color='black')\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KDfSHiUyvBn_"
      },
      "id": "KDfSHiUyvBn_",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}